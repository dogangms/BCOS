# üöÄ Decentralized AI Node Operating System

## üìã Project Overview

This project implements a **Decentralized AI Node Operating System** designed specifically for distributed AI and blockchain workloads. The system is built incrementally through multiple steps, each adding core operating system functionality.

### üéØ System Goals
- **Decentralized Architecture** - Support for distributed AI nodes
- **AI/Blockchain Optimized** - Specialized for AI inference and blockchain validation
- **Educational Focus** - Clear, documented implementation of OS concepts
- **Modular Design** - Step-by-step implementation for learning

### üóÇÔ∏è Implementation Steps
- ‚úÖ **Step 1**: Process Management (Complete)
- ‚úÖ **Step 2**: Memory Management (Complete)
- ‚úÖ **Step 3**: Concurrency & Synchronization (Complete)
- üîÑ **Step 4**: File System (Upcoming) 
- üîÑ **Step 5**: Network Communication (Upcoming)

---

## ‚úÖ Step 1: Process Management System

### üéØ **Objectives**
Implement core process management functionality including process creation, scheduling, switching, and termination with specialized support for AI and blockchain workloads.

### ‚ú® **Features Implemented**

#### Core Process Management
- **Process Control Block (PCB)** - Complete process information storage
- **Process Creation, Switching, and Termination** - Full process lifecycle management
- **Memory Simulation** - Basic memory allocation and deallocation
- **Process States** - NEW, READY, RUNNING, WAITING, TERMINATED, SUSPENDED

#### Scheduler Implementations
1. **FIFO (First In, First Out)** - Simple first-come-first-served scheduling
2. **Round Robin** - Time-slice based preemptive scheduling
3. **Priority Scheduler** - Priority-based scheduling with preemption
4. **Multi-Level Feedback Queue (MLFQ)** - Advanced scheduling with aging prevention

#### AI Node Specific Features
- **Themed Process Types** - AI_INFERENCE, DATA_PROCESSING, BLOCKCHAIN_VALIDATOR, NETWORK_NODE, SYSTEM, USER
- **Resource Requirements** - CPU, memory, GPU, and network bandwidth tracking
- **Node Management** - Unique node ID and connection tracking
- **Performance Metrics** - Comprehensive statistics and monitoring

#### Visualization & Monitoring
- **Real-time Dashboard** - Live system status visualization
- **Process Queue Visualization** - Visual representation of scheduler queues
- **Performance Statistics** - Wait time, turnaround time, throughput metrics
- **System State Export** - JSON export for analysis
- **Interactive Console** - Command-line interface for process management

### üèóÔ∏è **Architecture**

```
BCOS/
‚îú‚îÄ‚îÄ process_control_block.py    # PCB implementation with process states and types
‚îú‚îÄ‚îÄ schedulers.py              # All scheduler implementations
‚îú‚îÄ‚îÄ process_manager.py         # Main process manager with threading
‚îú‚îÄ‚îÄ process_visualizer.py      # Visualization and monitoring system
‚îú‚îÄ‚îÄ demo.py                   # Comprehensive demonstration script
‚îú‚îÄ‚îÄ test_basic.py             # Basic functionality tests
‚îî‚îÄ‚îÄ README.md                 # This documentation
```

### üéØ **Process Types**

The system supports specialized process types for decentralized AI nodes:

- üß† **AI_INFERENCE** - Machine learning inference tasks
- üìä **DATA_PROCESSING** - Data analysis and transformation
- ‚õìÔ∏è **BLOCKCHAIN_VALIDATOR** - Blockchain validation and mining
- üåê **NETWORK_NODE** - P2P network communication
- ‚öôÔ∏è **SYSTEM** - System maintenance and management
- üë§ **USER** - User-initiated processes

### üöÄ **Running Step 1**

#### Prerequisites
- Python 3.7+
- No external dependencies required (uses only standard library)

#### Quick Start
```bash
cd BCOS
python demo.py
```

#### Available Demo Modes
1. **FIFO Scheduler Demo** - Demonstrates first-in-first-out scheduling
2. **Round Robin Demo** - Shows time-slice based scheduling
3. **Priority Scheduler Demo** - Exhibits priority-based preemptive scheduling
4. **MLFQ Demo** - Multi-level feedback queue with aging
5. **Interactive Mode** - Command-line interface for real-time interaction
6. **All Demos** - Runs all scheduler demonstrations sequentially

#### Interactive Commands
```
create          - Create a new process
list            - List all active processes  
kill <pid>      - Terminate a process
suspend <pid>   - Suspend a process
resume <pid>    - Resume a suspended process
dashboard       - Show full system dashboard
monitor         - Start real-time monitoring
export          - Export system state to JSON
quit            - Exit the system
```

### üî¨ **Example Usage**

#### Basic Process Creation
```python
from process_manager import ProcessManager
from process_control_block import ProcessType
from schedulers import RoundRobinScheduler

# Initialize with Round Robin scheduler
manager = ProcessManager(RoundRobinScheduler(time_quantum=1000))
manager.start_scheduler()

# Create an AI inference process
def ai_task(model_name, data_size):
    print(f"Running {model_name} on {data_size} samples")
    # Your AI workload here
    return "Inference complete"

pid = manager.create_process(
    name="AI-GPT-4",
    process_type=ProcessType.AI_INFERENCE,
    target_function=ai_task,
    args=("GPT-4", 100),
    priority=5,
    memory_required=2048
)

# Monitor the process
info = manager.get_process_info(pid)
print(f"Process {pid}: {info}")

# Cleanup
manager.shutdown()
```

#### Scheduler Comparison
```python
from schedulers import FIFOScheduler, PriorityScheduler, MLFQScheduler

# Try different schedulers
schedulers = [
    FIFOScheduler(),
    PriorityScheduler(preemptive=True),
    MLFQScheduler(num_levels=3, time_quanta=[100, 200, 400])
]

for scheduler in schedulers:
    manager = ProcessManager(scheduler)
    # Create processes and compare performance
    stats = scheduler.get_statistics()
    print(f"{scheduler.name}: {stats}")
```

### üìä **Performance Metrics**

#### Process Metrics
- **Creation Time** - When process was created
- **CPU Time Used** - Total CPU time consumed
- **Wait Time** - Time spent waiting in queues
- **Turnaround Time** - Total time from creation to completion
- **Memory Usage** - Allocated memory size

#### Scheduler Metrics
- **Average Wait Time** - Mean time processes wait
- **Average Turnaround Time** - Mean total completion time
- **Throughput** - Processes completed per second
- **Context Switches** - Number of process switches

#### System Metrics
- **Memory Usage** - Total system memory utilization
- **Active Processes** - Currently running processes
- **Queue Lengths** - Processes waiting in each queue level
- **Uptime** - System operational time

### üé® **Visualization Features**

#### Dashboard Elements
- **System Header** - Node ID, scheduler type, uptime, context switches
- **Memory Status** - Usage bar and statistics
- **Process List** - All active processes with icons and states
- **Scheduler Queues** - Queue contents for each level
- **Performance Statistics** - Real-time metrics
- **AI Node Status** - Specialized process type counts

#### Process Icons & State Indicators
- üß† AI Inference processes | üÜï NEW - Just created
- üìä Data Processing tasks | ‚è≥ READY - Waiting to run
- ‚õìÔ∏è Blockchain Validators | üèÉ RUNNING - Currently executing
- üåê Network Nodes | ‚è∏Ô∏è WAITING - Blocked on I/O
- ‚öôÔ∏è System processes | üò¥ SUSPENDED - Temporarily stopped
- üë§ User tasks | üíÄ TERMINATED - Completed

### üß™ **Scheduler Comparison**

| Scheduler | Best For | Characteristics | Use Case |
|-----------|----------|-----------------|----------|
| **FIFO** | Batch processing | No preemption, run to completion | Background data processing |
| **Round Robin** | Interactive systems | Time-slice preemption, equal sharing | Multi-user AI inference |
| **Priority** | Different importance levels | Higher priority preempts lower | Critical blockchain validation |
| **MLFQ** | Mixed workload environments | Adaptive priority, prevents starvation | Decentralized AI/blockchain nodes |

### ‚úÖ **Step 1 Results**
- **Process Management**: ‚úÖ Complete with creation, switching, termination
- **Process Control Block**: ‚úÖ Comprehensive PCB implementation
- **Schedulers**: ‚úÖ 4 different algorithms implemented
- **Visualization**: ‚úÖ Real-time dashboard and monitoring
- **AI Node Features**: ‚úÖ Specialized process types and workloads
- **Performance Tracking**: ‚úÖ Comprehensive metrics and analysis

---

## ‚úÖ Step 2: Memory Management System

### üéØ **Objectives**
Implement comprehensive memory management with paging, address translation, virtual memory, swapping, and AI/blockchain-specific memory constraints.

### ‚ú® **Features Implemented**

#### Core Memory Management
- **Paging System** - 4KB page-based memory management
- **Page Tables** - Virtual to physical address translation
- **Virtual Memory** - Process isolation and address space management
- **Memory Allocation/Deallocation** - Dynamic memory management
- **Address Translation** - Hardware-simulated memory management unit (MMU)

#### Advanced Memory Features
- **Memory Swapping** - LRU-based page replacement with swap space
- **Memory Fragmentation Handling** - Detection and defragmentation algorithms
- **Memory Pools** - Specialized pools for different memory types
- **Memory Protection** - Read-only and access control mechanisms
- **Memory Statistics** - Comprehensive performance tracking

#### AI/Blockchain Memory Management
- **Themed Memory Constraints** - Separate limits for AI, blockchain, and system memory
- **Memory Type Classification** - 8 different memory types with performance tiers
- **Pinned Memory** - Critical AI models and blockchain data cannot be swapped
- **Performance Tiers** - Different access speeds for memory types
- **Dynamic Memory Allocation** - Runtime memory allocation for AI workloads

#### Memory Visualization
- **Memory Maps** - Visual representation of physical memory layout
- **Page Table Visualization** - Detailed page table information
- **Fragmentation Analysis** - Real-time fragmentation monitoring
- **Memory Pool Status** - Pool-specific usage and performance
- **Swap Space Monitoring** - Swap usage and operation tracking

### üèóÔ∏è **Architecture**

```
BCOS/
‚îú‚îÄ‚îÄ memory_manager.py           # Core memory management system
‚îú‚îÄ‚îÄ memory_visualizer.py        # Memory visualization and monitoring
‚îú‚îÄ‚îÄ memory_demo.py             # Comprehensive memory demonstrations
‚îú‚îÄ‚îÄ integrated_process_manager.py # Combined process + memory management
‚îú‚îÄ‚îÄ test_memory_management.py   # Memory system tests
‚îî‚îÄ‚îÄ README.md                  # This documentation
```

### üß† **Memory Types**

The system supports 8 specialized memory types for AI/blockchain workloads:

- ‚öôÔ∏è **SYSTEM** - Critical system operations (Tier 1, Pinned)
- üë§ **USER** - User application memory (Tier 1, Swappable)
- üß† **AI_MODEL** - Machine learning models (Tier 1, Pinned)
- üìä **AI_DATA** - Training and inference data (Tier 1, Swappable)
- ‚õìÔ∏è **BLOCKCHAIN_LEDGER** - Blockchain transaction data (Tier 2, Pinned)
- üîó **BLOCKCHAIN_STATE** - Smart contract state (Tier 2, Swappable)
- üåê **NETWORK_BUFFER** - P2P communication buffers (Tier 1, Swappable)
- üíæ **CACHE** - General purpose cache (Tier 1, Swappable)

### üìÑ **Page States**

- ‚¨ú **FREE** - Available for allocation
- üü© **ALLOCATED** - Currently in use
- üü® **SWAPPED** - Moved to swap space
- üü• **PINNED** - Cannot be swapped (critical data)
- üüß **DIRTY** - Modified, needs write-back
- üü¶ **SHARED** - Shared between processes

### üöÄ **Running Step 2**

#### Prerequisites
- Python 3.7+
- No external dependencies required

#### Quick Start
```bash
cd BCOS
python memory_demo.py
```

#### Available Demo Modes
1. **Basic Paging and Address Translation** - Core memory operations
2. **Memory Types and Constraints** - AI/blockchain memory limits
3. **Swapping and Virtual Memory** - Page replacement and virtual memory
4. **Fragmentation and Defragmentation** - Memory fragmentation handling
5. **Specialized Memory Pools** - Pool-based memory management
6. **Performance Analysis** - Memory performance metrics
7. **Interactive Memory Management** - Real-time memory operations

#### Interactive Memory Commands
```
allocate <size> <type>  - Allocate memory of specific type
deallocate <pid>        - Deallocate process memory
access <pid> <offset>   - Access memory at offset
dashboard               - Show full memory dashboard
fragmentation          - Show fragmentation analysis
defrag                 - Perform memory defragmentation
export                 - Export memory state to JSON
monitor                - Start real-time memory monitoring
quit                   - Exit interactive demo
```

### üî¨ **Example Usage**

#### Basic Memory Operations
```python
from memory_manager import MemoryManager, MemoryType

# Initialize memory manager
memory_manager = MemoryManager(total_memory=1024*1024*1024, page_size=4096)

# Allocate memory for AI model
process_id = 1001
virtual_address = memory_manager.allocate_memory(
    process_id, 
    size=10*1024*1024,  # 10MB
    memory_type=MemoryType.AI_MODEL
)

# Access memory
success, data = memory_manager.access_memory(process_id, virtual_address)
print(f"Memory access: {'Success' if success else 'Failed'}")

# Get memory statistics
stats = memory_manager.get_memory_statistics()
print(f"Memory usage: {stats['memory_usage_percent']:.1f}%")
```

#### Integrated Process and Memory Management
```python
from integrated_process_manager import IntegratedProcessManager
from process_control_block import ProcessType

# Initialize integrated manager
manager = IntegratedProcessManager(
    total_memory=2*1024*1024*1024,  # 2GB
    page_size=4096
)

# Create AI inference process with automatic memory allocation
def ai_inference_task():
    # Simulate AI model loading and inference
    return "Inference complete"

pid = manager.create_process(
    name="AI-GPT-Inference",
    process_type=ProcessType.AI_INFERENCE,
    target_function=ai_inference_task,
    memory_required=50*1024*1024  # 50MB
)

# Memory type is automatically set to AI_MODEL based on process type
process_info = manager.get_process_info(pid)
print(f"Process {pid} allocated at: 0x{process_info['virtual_base_address']:08X}")
print(f"Memory type: {process_info['memory_type'].value}")

# Allocate additional memory for the process
additional_addr = manager.allocate_additional_memory(pid, 10*1024*1024)
print(f"Additional memory at: 0x{additional_addr:08X}")
```

#### Memory Visualization
```python
from memory_visualizer import MemoryVisualizer

visualizer = MemoryVisualizer(memory_manager)

# Display comprehensive memory dashboard
visualizer.display_full_memory_dashboard()

# Show specific visualizations
visualizer.display_memory_map(scale=64)
visualizer.display_fragmentation_analysis()
visualizer.display_ai_memory_constraints()

# Export memory state
visualizer.export_memory_state("memory_state.json")

# Start real-time monitoring
visualizer.real_time_memory_monitor(refresh_interval=2.0)
```

### üìä **Memory Constraints**

The system enforces AI/blockchain-specific memory constraints:

| Memory Category | Allocation Limit | Purpose |
|----------------|------------------|---------|
| **AI Total** | 60% of system memory | AI models + data |
| **AI Models** | 24% of system memory | Critical ML models (pinned) |
| **AI Data** | 36% of system memory | Training/inference data |
| **Blockchain Total** | 30% of system memory | Blockchain operations |
| **Blockchain Ledger** | 18% of system memory | Transaction data (pinned) |
| **Blockchain State** | 12% of system memory | Smart contract state |
| **System** | 10% of system memory | OS operations (pinned) |

### üéØ **Performance Features**

#### Memory Access Performance
- **Tier 1 (Fastest)**: 0.1-0.3ms access time - AI models, system, network buffers
- **Tier 2 (Medium)**: 1.5-2.0ms access time - Blockchain ledger and state
- **Cache Access**: 0.15ms access time - Optimized cache memory

#### Memory Management Algorithms
- **LRU Page Replacement** - Least Recently Used algorithm for swapping
- **First-Fit Allocation** - Efficient memory allocation strategy
- **Defragmentation** - Automated memory compaction
- **Aging Prevention** - Prevents starvation in swapping decisions

#### Performance Monitoring
- **Page Fault Rate** - Frequency of page faults
- **Swap I/O Operations** - Swap-in and swap-out tracking
- **Fragmentation Level** - Real-time fragmentation measurement
- **Memory Efficiency** - Overall system memory efficiency

### üß™ **Memory Pool Configuration**

| Pool Name | Size | Performance Tier | Pinned | Purpose |
|-----------|------|------------------|--------|---------|
| **AI Models** | 25% of memory | Tier 1 | Yes | ML model storage |
| **AI Data** | 33% of memory | Tier 1 | No | Training data |
| **Blockchain Ledger** | 17% of memory | Tier 2 | Yes | Transaction history |
| **Blockchain State** | 13% of memory | Tier 2 | No | Contract state |
| **Network Buffers** | 10% of memory | Tier 1 | No | P2P communication |
| **System** | 5% of memory | Tier 1 | Yes | OS operations |

### üé® **Visualization Features**

#### Memory Dashboard Elements
- **Memory Header** - System overview with statistics
- **Physical Memory Map** - Visual representation of memory layout
- **Memory Pools Status** - Pool-specific usage and performance
- **Page Table Information** - Virtual memory mappings
- **Fragmentation Analysis** - Memory holes and defragmentation status
- **Swap Space Monitoring** - Swap usage and performance
- **AI/Blockchain Constraints** - Memory limit enforcement status

#### Real-time Monitoring
- **Live Memory Usage** - Continuously updated memory statistics
- **Performance Graphs** - ASCII-based performance visualization
- **Memory Access Patterns** - Real-time access monitoring
- **Alert System** - Warnings for high fragmentation or swap usage

### üß™ **Testing and Validation**

#### Comprehensive Test Suite
```bash
# Run all memory management tests
python test_memory_management.py

# Test specific components
python -c "from memory_manager import MemoryManager; print('Memory manager loaded')"
python -c "from integrated_process_manager import IntegratedProcessManager; print('Integration works')"
```

#### Performance Benchmarks
- **Memory Allocation**: 100+ allocations per second
- **Address Translation**: 1000+ translations per second
- **Memory Access**: 500+ accesses per second
- **Defragmentation**: Completes in <1 second for 16MB memory

### ‚úÖ **Step 2 Results**
- **Paging System**: ‚úÖ Complete with 4KB pages and page tables
- **Address Translation**: ‚úÖ Virtual to physical address mapping
- **Memory Swapping**: ‚úÖ LRU-based page replacement with swap space
- **Fragmentation Handling**: ‚úÖ Detection, analysis, and defragmentation
- **AI/Blockchain Constraints**: ‚úÖ Themed memory limits and pools
- **Memory Visualization**: ‚úÖ Comprehensive dashboards and monitoring
- **Integration**: ‚úÖ Seamless process-memory management integration
- **Performance**: ‚úÖ Optimized for AI/blockchain workloads

---

## ‚úÖ Step 3: Concurrency & Synchronization

### üéØ **Objectives**
Implement advanced threading API, synchronization primitives, classical concurrency problems, and real-time monitoring for multi-threaded AI and blockchain operations.

### ‚ú® **Features Implemented**

#### Thread API
- **AI Thread Control Block** - Enhanced thread metadata with AI/blockchain specific metrics
- **Thread Management** - Creation, starting, joining, suspending, and terminating threads
- **Thread Types** - AI_WORKER, BLOCKCHAIN_MINER, NETWORK_HANDLER, DATA_PROCESSOR, CONSENSUS_NODE, SMART_CONTRACT, SYSTEM_DAEMON, USER_THREAD
- **Priority Levels** - CRITICAL, HIGH, NORMAL, LOW, IDLE with priority-based scheduling
- **Performance Tracking** - CPU time, memory usage, AI operations, blockchain transactions

#### Synchronization Primitives
- **Locks** - Mutual exclusion with deadlock prevention
- **Condition Variables** - Thread signaling and coordination
- **Semaphores** - Resource counting and access control
- **Barriers** - Multi-thread synchronization points

#### Classical Concurrency Problems
1. **Producer-Consumer (AI Data Processing)** - AI training data generation and processing
2. **Dining Philosophers (AI Node Consensus)** - Blockchain consensus with shared resource access
3. **Readers-Writers (AI Model Access)** - Multiple readers, few writers for shared AI models

#### Real-time Visualization & Monitoring
- **Thread Dashboard** - Live thread status, CPU utilization, lock status
- **Lock Monitor** - Lock contention tracking and deadlock detection
- **Condition Variable Tracker** - CV signaling and waiting thread monitoring
- **Deadlock Detector** - Cycle detection in wait-for graphs
- **Performance Graphs** - ASCII charts for throughput, utilization, contention
- **Timeline View** - Chronological synchronization event tracking

#### Multi-threaded OS Tasks (Creativity Feature)
- **File I/O Simulation** - Concurrent file operations with proper synchronization
- **UI Update Threads** - Simulated user interface updates with thread coordination
- **Network Operations** - Concurrent network request handling with connection pooling

### üèóÔ∏è **Architecture**

```
BCOS/
‚îú‚îÄ‚îÄ thread_api.py                  # Core threading API and thread management
‚îú‚îÄ‚îÄ concurrency_problems.py       # Classical concurrency problem implementations
‚îú‚îÄ‚îÄ synchronization_visualizer.py # Real-time monitoring and visualization
‚îú‚îÄ‚îÄ step3_demo.py                 # Comprehensive Step 3 demonstration
‚îú‚îÄ‚îÄ test_step3.py                 # Complete test suite for Step 3
‚îî‚îÄ‚îÄ [Step 1 & 2 files...]         # Previous components
```

### üßµ **Thread Types & Use Cases**

#### AI/Blockchain Specialized Threads
- ü§ñ **AI_WORKER** - Neural network training, inference operations
- ‚õèÔ∏è **BLOCKCHAIN_MINER** - Cryptocurrency mining, block generation
- üåê **NETWORK_HANDLER** - P2P communication, node discovery
- üìä **DATA_PROCESSOR** - Dataset transformation, feature extraction
- üîó **CONSENSUS_NODE** - Blockchain consensus participation
- üìú **SMART_CONTRACT** - Contract execution and validation
- ‚öôÔ∏è **SYSTEM_DAEMON** - Background system maintenance
- üë§ **USER_THREAD** - User-initiated operations

### üîí **Synchronization Scenarios**

#### AI Training Coordination
```python
# Producer-Consumer for AI training data
producer_consumer = ProducerConsumerAI(
    buffer_size=10,
    num_producers=3,  # Data generators
    num_consumers=2   # Model trainers
)
```

#### Blockchain Consensus
```python  
# Dining Philosophers for blockchain consensus
dining_philosophers = DiningPhilosophersAI(
    num_philosophers=5  # Consensus nodes
)
```

#### Model Access Control
```python
# Readers-Writers for AI model access
readers_writers = ReadersWritersAI(
    num_readers=5,  # Inference services
    num_writers=2   # Model update services
)
```

### üöÄ **Running Step 3**

#### Prerequisites
- Python 3.7+
- Step 1 and Step 2 components
- No external dependencies (uses standard library)

#### Quick Start
```bash
cd BCOS
python step3_demo.py
```

#### Demo Menu Options
1. **Thread API Basics** - Basic threading functionality demonstration
2. **Synchronization Primitives** - Locks, condition variables, semaphores
3. **Producer-Consumer Problem** - AI data processing simulation
4. **Dining Philosophers Problem** - Blockchain consensus simulation
5. **Readers-Writers Problem** - AI model access control
6. **Real-time Monitoring Dashboard** - Live system visualization
7. **Interactive Concurrency Simulation** - Multi-problem with live monitoring
8. **All Problems Sequential** - Complete suite demonstration
9. **Multi-threaded OS Tasks** - Creativity feature with I/O, UI, network

### üî¨ **Example Usage**

#### Basic Threading with Synchronization
```python
from thread_api import ThreadAPI, ThreadType, ThreadPriority

# Initialize thread API
thread_api = ThreadAPI()

# Create shared resources
thread_api.create_lock("model_lock")
thread_api.create_condition_variable("training_complete", "model_lock")

def ai_trainer(model_name, epochs):
    """AI training task with synchronization"""
    thread_id = threading.current_thread().name
    
    # Acquire model lock
    if thread_api.acquire_lock("model_lock", thread_id):
        try:
            print(f"Training {model_name} for {epochs} epochs")
            # Simulate training
            time.sleep(2.0)
            print(f"Training complete: {model_name}")
            
            # Notify other threads
            thread_api.notify_condition("training_complete", notify_all=True)
        finally:
            thread_api.release_lock("model_lock", thread_id)

# Create AI worker thread
trainer_id = thread_api.create_thread(
    function=ai_trainer,
    args=("GPT-5", 100),
    name="AI-Trainer-1",
    thread_type=ThreadType.AI_WORKER,
    priority=ThreadPriority.HIGH
)

# Start and monitor
thread_api.start_thread(trainer_id)
thread_api.join_thread(trainer_id)
```

#### Real-time Monitoring
```python
from synchronization_visualizer import SynchronizationVisualizer, InteractiveMonitor

# Create visualizer
visualizer = SynchronizationVisualizer(thread_api)
monitor = InteractiveMonitor(visualizer)

# Start interactive monitoring
monitor.start_interactive_mode()

# Switch between visualization modes:
# [1] Thread Dashboard  [2] Lock Monitor  [3] Condition Tracker
# [4] Deadlock Detector [5] Performance  [6] Timeline
```

### üìä **Monitoring & Visualization**

#### Thread Dashboard Features
- **System Overview** - Uptime, active threads, CPU utilization, lock count
- **Thread State Summary** - Visual thread state distribution with emojis
- **Active Thread Details** - ID, name, type, priority, CPU time, locks held
- **Thread Type Distribution** - Bar chart of thread types

#### Synchronization Monitoring
- **Lock Status** - Lock availability, holders, waiting threads
- **Condition Variable Tracking** - Waiting threads, recent notifications
- **Deadlock Detection** - Cycle detection with involved threads
- **Performance Graphs** - ASCII charts for throughput and contention

#### Event Timeline
- **Synchronization Events** - Lock acquire/release, condition wait/notify
- **Thread State Changes** - Creation, termination, state transitions
- **Performance Metrics** - Wait times, lock contention, deadlock warnings

### üß™ **Testing**

#### Run Complete Test Suite
```bash
python test_step3.py
```

#### Test Categories
- **Thread API Tests** - Thread creation, execution, lifecycle management
- **Synchronization Tests** - Lock, condition variable, semaphore functionality
- **Concurrency Problem Tests** - Producer-Consumer, Dining Philosophers, Readers-Writers
- **Visualization Tests** - Event tracking, snapshot functionality
- **Integration Tests** - Realistic concurrent scenarios, performance under load

### üìà **Performance Metrics**

#### Threading Metrics
- **Thread Lifecycle** - Creation time, execution time, completion time
- **Resource Usage** - Memory usage, CPU time, lock contention
- **AI/Blockchain Metrics** - Operations completed, transactions processed

#### Synchronization Metrics
- **Lock Statistics** - Acquisition time, hold time, contention count
- **Condition Variable Stats** - Wait time, notification count
- **Deadlock Detection** - Potential deadlocks, dependency cycles

#### System Performance
- **Throughput** - Operations per second, thread completion rate
- **Utilization** - CPU usage, memory usage, lock utilization
- **Contention** - Lock contention percentage, wait times

---

## üîÑ Step 4: File System

### ÔøΩÔøΩ **Objectives** (Upcoming)
*Will be implemented in the next phase*

### üìã **Planned Features**
- Virtual File System
- AI Model Storage and Caching
- Blockchain Data Management
- File Allocation and Organization

---

## üîÑ Step 5: Network Communication

### üéØ **Objectives** (Upcoming)
*Will be implemented in a future phase*

### üìã **Planned Features**
- P2P Network Protocol
- Inter-node Communication
- Distributed Process Migration
- Network Security and Encryption

---

## üîß Installation & Development

### Prerequisites
- Python 3.7 or higher
- Standard library only (no external dependencies)

### Development Setup
```bash
# Clone the repository
git clone <repository-url>
cd BlockchainOS/BCOS

# Run tests
python test_basic.py
python test_memory_management.py

# Start interactive demo
python demo.py
python memory_demo.py
```

### Testing
```bash
# Run basic functionality tests
python test_basic.py

# Run memory management tests
python test_memory_management.py

# Test individual components
python -c "from schedulers import *; print('Schedulers loaded successfully')"
python -c "from memory_manager import *; print('Memory manager loaded successfully')"
```

---

## ü§ù Contributing

This project welcomes contributions for:

### Current (Steps 1 & 2)
- Additional scheduler algorithms
- Memory allocation optimizations
- Enhanced visualization features
- Better AI/ML workload simulation
- Performance improvements

### Future Steps
- File system implementations
- Network protocols
- Security enhancements
- Distributed computing features

---

## üìö Learning Resources

This project demonstrates key operating system concepts:

1. **Process Management** - Scheduling algorithms, context switching
2. **Memory Management** - Paging, virtual memory, swapping
3. **System Calls** - Process and memory management APIs
4. **Concurrency** - Multi-threading and synchronization
5. **Performance Analysis** - Metrics collection and visualization
6. **System Design** - Modular architecture and clean interfaces

---

## üìù License

This project is part of an educational operating system development series focused on decentralized AI and blockchain applications.

---

## üìä Current Status

| Component | Status | Features | Performance |
|-----------|--------|----------|-------------|
| **Step 1: Process Management** | ‚úÖ Complete | 4 schedulers, visualization, AI workloads | Excellent |
| **Step 2: Memory Management** | ‚úÖ Complete | Paging, swapping, AI constraints, visualization | Excellent |
| **Step 3: Concurrency & Synchronization** | ‚úÖ Complete | Thread API, synchronization primitives, AI/blockchain tasks | Excellent |
| **Step 4: File System** | üîÑ Planned | Distributed storage, AI model caching | - |
| **Step 5: Network Communication** | üîÑ Planned | P2P protocols, inter-node communication | - |

**Current Milestone**: Step 3 Complete ‚úÖ  
**Next Milestone**: Step 4 - File System Implementation  
**Project Completion**: 50% (3/5 major steps)