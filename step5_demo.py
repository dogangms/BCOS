"""
Decentralized AI Node Operating System - Step 5: Bonus Features Demo
Demonstrates AI-based scheduler and Web GUI dashboard for the operating system.
"""

import time
import threading
import random
from typing import Optional

# Import all system components
from file_system import VirtualFileSystem, FileType, AccessLevel
from file_encryption import FileEncryption, EncryptionLevel
from ai_scheduler import AIScheduler, LearningMode, ProcessType
from web_gui import create_integrated_gui

class Step5Demo:
    """
    Step 5 Bonus Features Demo
    Showcases AI-based intelligent scheduler and modern web-based GUI
    """
    
    def __init__(self):
        print("üöÄ Initializing Decentralized AI Node OS - Step 5 Bonus Features...")
        
        # Initialize all system components
        self.file_system = VirtualFileSystem(total_blocks=2048, block_size=4096)
        self.encryption = FileEncryption()
        self.ai_scheduler = AIScheduler(num_cores=8)  # 8-core simulation
        self.web_gui = None
        
        # Demo state
        self.demo_running = False
        self.workload_thread = None
        
        print("‚úÖ System components initialized successfully!")
        
    def run_comprehensive_demo(self):
        """Run the complete Step 5 bonus features demonstration"""
        print("\nüéØ " + "STEP 5: BONUS FEATURES DEMONSTRATION".center(80, "‚ïê"))
        print("üß† AI-Based Intelligent Scheduler + üñ•Ô∏è Web GUI Dashboard")
        print("=" * 80)
        
        while True:
            print("\nüìã BONUS FEATURES MENU:")
            print("  [1] ü§ñ AI Scheduler Intelligence Demo")
            print("  [2] üñ•Ô∏è Web GUI Dashboard Demo")
            print("  [3] üéÆ Interactive AI Learning Demo")
            print("  [4] üìä Performance Comparison Demo")
            print("  [5] üåê Integrated Web Dashboard")
            print("  [6] üöÄ Full System Simulation")
            print("  [7] üìà AI Learning Analytics")
            print("  [0] Exit Demo")
            print()
            
            choice = input("üéØ Select demo option: ").strip()
            
            if choice == '1':
                self.demo_ai_scheduler()
            elif choice == '2':
                self.demo_web_gui()
            elif choice == '3':
                self.demo_interactive_ai_learning()
            elif choice == '4':
                self.demo_performance_comparison()
            elif choice == '5':
                self.demo_integrated_dashboard()
            elif choice == '6':
                self.demo_full_system_simulation()
            elif choice == '7':
                self.demo_ai_analytics()
            elif choice == '0':
                self.cleanup()
                print("üëã Exiting Step 5 bonus features demo...")
                break
            else:
                print("‚ùå Invalid choice, please try again.")
                
            print("\n" + "‚îÄ" * 80 + "\n")
            
    def demo_ai_scheduler(self):
        """Demonstrate AI-based intelligent scheduler capabilities"""
        print("ü§ñ AI-BASED INTELLIGENT SCHEDULER DEMONSTRATION")
        print("‚ïê" * 60)
        
        print("üîÑ Setting up AI scheduler demonstration...")
        
        # Show initial scheduler state
        print("\nüìä Initial AI Scheduler State:")
        metrics = self.ai_scheduler.get_ai_metrics()
        self._display_scheduler_metrics(metrics)
        
        # Add various process types
        print("\nüîÑ Adding diverse AI/blockchain workloads...")
        
        process_types = [
            (ProcessType.AI_WORKER, "Neural network training", 2.5),
            (ProcessType.BLOCKCHAIN_MINER, "Block mining operation", 3.0),
            (ProcessType.SMART_CONTRACT, "Smart contract execution", 1.0),
            (ProcessType.AI_WORKER, "Model inference", 0.8),
            (ProcessType.NETWORK_HANDLER, "P2P communication", 1.5),
            (ProcessType.BLOCKCHAIN_MINER, "Transaction validation", 2.0),
            (ProcessType.AI_WORKER, "Data preprocessing", 1.8),
            (ProcessType.SMART_CONTRACT, "DeFi protocol execution", 1.2)
        ]
        
        for i, (ptype, description, estimated_time) in enumerate(process_types):
            self.ai_scheduler.add_process(
                f"proc_{i+1:02d}_{ptype.value}",
                ptype,
                estimated_time,
                random.uniform(100, 500)
            )
            print(f"  ‚úÖ Added: {description} (Type: {ptype.value})")
            
        print(f"\nüìà Queue Status: {len(self.ai_scheduler.ready_queue)} processes ready")
        
        # Demonstrate intelligent scheduling
        print("\nüß† AI Scheduler Making Intelligent Decisions...")
        scheduled_count = 0
        
        for _ in range(8):  # Schedule up to 8 processes (one per core)
            scheduled = self.ai_scheduler.schedule_next()
            if scheduled:
                scheduled_count += 1
                ptype_str = scheduled["type"].value if hasattr(scheduled["type"], "value") else str(scheduled["type"])
                print(f"  üéØ Scheduled {scheduled['id']} ({ptype_str}) on Core {scheduled['core_id']}")
                print(f"     Priority: {scheduled['priority']}, Power: {scheduled['power_state']}")
                print(f"     Predicted Runtime: {scheduled['predicted_runtime']:.2f}s")
                
                # Simulate process execution
                threading.Thread(
                    target=self._simulate_ai_process,
                    args=(scheduled,),
                    daemon=True
                ).start()
                
            time.sleep(0.5)  # Small delay for demonstration
            
        print(f"\n‚úÖ Scheduled {scheduled_count} processes across {self.ai_scheduler.num_cores} cores")
        
        # Show learning in action
        print("\nüß† AI Learning in Progress...")
        time.sleep(3)  # Wait for some processes to complete
        
        updated_metrics = self.ai_scheduler.get_ai_metrics()
        print("\nüìä Updated AI Scheduler Metrics:")
        self._display_scheduler_metrics(updated_metrics)
        
        # Show learning improvements
        if updated_metrics["successful_predictions"] > 0:
            accuracy = updated_metrics["prediction_accuracy"]
            print(f"\nüéØ AI Prediction Accuracy: {accuracy:.1f}%")
            print("üí° The AI is learning from process execution patterns!")
            
    def demo_web_gui(self):
        """Demonstrate web-based GUI dashboard"""
        print("üñ•Ô∏è WEB-BASED GUI DASHBOARD DEMONSTRATION")
        print("‚ïê" * 60)
        
        if self.web_gui and self.web_gui.running:
            print("‚ÑπÔ∏è Web GUI is already running!")
            print(f"üåê Dashboard URL: http://localhost:{self.web_gui.port}")
        else:
            print("üîÑ Starting web-based dashboard server...")
            
            # Create some demo data first
            self._create_demo_data()
            
            # Start web GUI
            self.web_gui = create_integrated_gui(
                self.file_system,
                self.encryption,
                self.ai_scheduler,
                port=8080
            )
            
            self.web_gui.start_server()
            
            print("‚úÖ Web GUI Dashboard is now running!")
            print(f"üåê Open your browser to: http://localhost:8080")
            print()
            print("üìä Dashboard Features:")
            print("  ‚Ä¢ Real-time system monitoring with animated progress rings")
            print("  ‚Ä¢ AI scheduler performance metrics and learning status")
            print("  ‚Ä¢ File system storage analytics with interactive charts")
            print("  ‚Ä¢ Security dashboard with encryption statistics")
            print("  ‚Ä¢ Live process monitoring table")
            print("  ‚Ä¢ Modern responsive design with gradient themes")
            
        print("\n‚è±Ô∏è Starting background system activity for live demonstration...")
        self._start_background_activity()
        
        print("\nüéÆ The dashboard will update every 2 seconds with real system data!")
        print("üì± Try resizing your browser window to see responsive design!")
        
        input("\n‚è≥ Press Enter when you've explored the dashboard...")
        
    def demo_interactive_ai_learning(self):
        """Demonstrate interactive AI learning capabilities"""
        print("üéÆ INTERACTIVE AI LEARNING DEMONSTRATION")
        print("‚ïê" * 60)
        
        print("üß† This demo shows how the AI scheduler adapts and learns!")
        print("\nüîÑ Setting up different learning scenarios...")
        
        # Test different learning modes
        learning_modes = [
            (LearningMode.AI_FOCUSED, "AI workload optimization"),
            (LearningMode.BLOCKCHAIN_FOCUSED, "Blockchain efficiency focus"),
            (LearningMode.POWER_SAVING, "Power consumption minimization"),
            (LearningMode.BALANCED, "Balanced performance optimization")
        ]
        
        for mode, description in learning_modes:
            print(f"\nüéØ Testing {mode.value} - {description}")
            self.ai_scheduler.set_learning_mode(mode)
            
            # Add mode-specific workload
            if mode == LearningMode.AI_FOCUSED:
                for i in range(5):
                    self.ai_scheduler.add_process(
                        f"ai_focus_{i}",
                        ProcessType.AI_WORKER,
                        random.uniform(1.0, 3.0)
                    )
            elif mode == LearningMode.BLOCKCHAIN_FOCUSED:
                for i in range(4):
                    self.ai_scheduler.add_process(
                        f"blockchain_focus_{i}",
                        ProcessType.BLOCKCHAIN_MINER,
                        random.uniform(2.0, 4.0)
                    )
                    
            # Schedule and execute processes
            scheduled_in_mode = 0
            for _ in range(3):
                scheduled = self.ai_scheduler.schedule_next()
                if scheduled:
                    scheduled_in_mode += 1
                    ptype_str = scheduled["type"].value if hasattr(scheduled["type"], "value") else str(scheduled["type"])
                    print(f"  üìã Scheduled: {scheduled['id']} ({ptype_str}) - Priority: {scheduled['priority']}")
                    
                    # Quick execution simulation
                    threading.Thread(
                        target=self._simulate_ai_process,
                        args=(scheduled,),
                        daemon=True
                    ).start()
                    
            print(f"  ‚úÖ Processed {scheduled_in_mode} tasks in {mode.value} mode")
            time.sleep(2)  # Wait for completion
            
        # Show learning results
        print("\nüìà AI Learning Results:")
        final_metrics = self.ai_scheduler.get_ai_metrics()
        print(f"üéØ Total Adaptations: {final_metrics['adaptation_count']}")
        print(f"üß† Learning Rate: {final_metrics['learning_rate']:.3f}")
        print(f"üìä Performance Score: {final_metrics['avg_performance_score']:.1f}")
        print(f"üîÑ Mode: {final_metrics['learning_mode']}")
        
        if final_metrics['adaptation_count'] > 0:
            print("\nüí° The AI successfully adapted its strategy based on workload patterns!")
        
    def demo_performance_comparison(self):
        """Demonstrate performance comparison between traditional and AI scheduling"""
        print("üìä AI SCHEDULER PERFORMANCE COMPARISON")
        print("‚ïê" * 60)
        
        print("üîÑ Running performance comparison: Traditional vs AI Scheduling")
        
        # Simulate traditional scheduling (simple FIFO)
        print("\nüìà Phase 1: Traditional FIFO Scheduling Simulation")
        traditional_metrics = self._simulate_traditional_scheduling()
        
        print("\nüß† Phase 2: AI-Based Intelligent Scheduling")
        ai_metrics = self._simulate_ai_scheduling()
        
        # Compare results
        print("\nüìä PERFORMANCE COMPARISON RESULTS:")
        print("=" * 50)
        
        comparison_data = [
            ("üìã Total Processes", traditional_metrics['total'], ai_metrics['total']),
            ("‚ö° Avg Response Time", f"{traditional_metrics['avg_response']:.2f}s", f"{ai_metrics['avg_response']:.2f}s"),
            ("üéØ Success Rate", f"{traditional_metrics['success_rate']:.1f}%", f"{ai_metrics['success_rate']:.1f}%"),
            ("üîã Power Efficiency", f"{traditional_metrics['power_score']:.1f}", f"{ai_metrics['power_score']:.1f}"),
            ("üíæ Resource Utilization", f"{traditional_metrics['utilization']:.1f}%", f"{ai_metrics['utilization']:.1f}%")
        ]
        
        print(f"{'Metric':<25} {'Traditional':<15} {'AI-Based':<15} {'Improvement'}")
        print("-" * 70)
        
        for metric, trad_val, ai_val in comparison_data:
            if metric == "üìã Total Processes":
                improvement = "Same"
            else:
                try:
                    trad_num = float(trad_val.split('%')[0].split('s')[0])
                    ai_num = float(ai_val.split('%')[0].split('s')[0])
                    
                    if "Time" in metric:
                        improvement = f"{((trad_num - ai_num) / trad_num * 100):+.1f}%"
                    else:
                        improvement = f"{((ai_num - trad_num) / trad_num * 100):+.1f}%"
                except:
                    improvement = "N/A"
                    
            print(f"{metric:<25} {trad_val:<15} {ai_val:<15} {improvement}")
            
        print("\nüèÜ Summary:")
        if ai_metrics['avg_response'] < traditional_metrics['avg_response']:
            print("‚úÖ AI scheduler shows improved response times!")
        if ai_metrics['success_rate'] > traditional_metrics['success_rate']:
            print("‚úÖ AI scheduler achieves higher success rates!")
        if ai_metrics['power_score'] > traditional_metrics['power_score']:
            print("‚úÖ AI scheduler demonstrates better power efficiency!")
            
    def demo_integrated_dashboard(self):
        """Demonstrate integrated web dashboard with all components"""
        print("üåê INTEGRATED WEB DASHBOARD DEMONSTRATION")
        print("‚ïê" * 60)
        
        print("üîÑ Setting up integrated system demonstration...")
        
        # Ensure web GUI is running
        if not self.web_gui or not self.web_gui.running:
            self._create_demo_data()
            self.web_gui = create_integrated_gui(
                self.file_system,
                self.encryption,
                self.ai_scheduler,
                port=8080
            )
            self.web_gui.start_server()
            
        # Start comprehensive background activity
        print("üéÆ Starting comprehensive system simulation...")
        self._start_comprehensive_simulation()
        
        print("\nüåü INTEGRATED DASHBOARD FEATURES:")
        print("=" * 50)
        print("üìä Real-time System Monitoring:")
        print("  ‚Ä¢ Animated CPU, Memory, Disk, and Network usage rings")
        print("  ‚Ä¢ Live system uptime counter")
        print("  ‚Ä¢ Dynamic progress indicators")
        print()
        print("ü§ñ AI Scheduler Intelligence:")
        print("  ‚Ä¢ Live performance chart with real-time updates")
        print("  ‚Ä¢ Learning mode and prediction accuracy display")
        print("  ‚Ä¢ Adaptation count and process statistics")
        print()
        print("üìÅ File System Analytics:")
        print("  ‚Ä¢ Interactive storage utilization donut chart")
        print("  ‚Ä¢ Real-time file operation monitoring")
        print("  ‚Ä¢ Cache performance statistics")
        print()
        print("üîí Security Dashboard:")
        print("  ‚Ä¢ Encryption status and active keys count")
        print("  ‚Ä¢ Security success rate monitoring")
        print("  ‚Ä¢ Blocked users and threat detection")
        print()
        print("‚öôÔ∏è Process Monitor:")
        print("  ‚Ä¢ Live process table with running and queued processes")
        print("  ‚Ä¢ Process type icons and power mode indicators")
        print("  ‚Ä¢ Real-time runtime tracking")
        
        print(f"\nüåê Dashboard URL: http://localhost:8080")
        print("üì± The dashboard is fully responsive and updates every 2 seconds!")
        
        input("\n‚è≥ Press Enter after exploring the integrated dashboard...")
        
    def demo_full_system_simulation(self):
        """Run full system simulation with all components"""
        print("üöÄ FULL SYSTEM SIMULATION")
        print("‚ïê" * 60)
        
        print("üîÑ Launching comprehensive system simulation...")
        print("This demonstrates all bonus features working together in harmony!")
        
        # Ensure all components are running
        if not self.web_gui or not self.web_gui.running:
            self._create_demo_data()
            self.web_gui = create_integrated_gui(
                self.file_system,
                self.encryption,
                self.ai_scheduler,
                port=8080
            )
            self.web_gui.start_server()
            
        # Run AI scheduler simulation
        print("\nü§ñ Starting AI scheduler workload simulation...")
        self.ai_scheduler.simulate_workload(duration=10.0)
        
        # Create file system activity
        print("üìÅ Generating file system activity...")
        self._generate_file_activity()
        
        # Show real-time statistics
        print("\nüìä LIVE SYSTEM STATISTICS:")
        for i in range(10):
            print(f"\rüîÑ Update {i+1}/10", end="", flush=True)
            
            # Get current metrics
            scheduler_metrics = self.ai_scheduler.get_ai_metrics()
            fs_metrics = self.file_system.get_file_system_stats()
            security_metrics = self.encryption.get_security_statistics()
            
            time.sleep(1)
            
        print("\n")
        
        # Final summary
        print("üèÅ SIMULATION SUMMARY:")
        print("=" * 40)
        print(f"ü§ñ AI Scheduler:")
        print(f"  ‚Ä¢ Processed: {scheduler_metrics['total_scheduled']} processes")
        print(f"  ‚Ä¢ Accuracy: {scheduler_metrics['prediction_accuracy']:.1f}%")
        print(f"  ‚Ä¢ Adaptations: {scheduler_metrics['adaptation_count']}")
        print()
        print(f"üìÅ File System:")
        print(f"  ‚Ä¢ Files: {fs_metrics['total_files']}")
        print(f"  ‚Ä¢ Storage: {fs_metrics['storage_utilization']:.1f}% used")
        print(f"  ‚Ä¢ Cache Rate: {fs_metrics['cache_hit_rate']:.1f}%")
        print()
        print(f"üîí Security:")
        print(f"  ‚Ä¢ Encrypted Files: {security_metrics['encrypted_files']}")
        print(f"  ‚Ä¢ Success Rate: {security_metrics['success_rate']:.1f}%")
        print(f"  ‚Ä¢ Active Keys: {security_metrics['total_encryption_keys']}")
        
        print(f"\nüåê View live dashboard: http://localhost:8080")
        
    def demo_ai_analytics(self):
        """Demonstrate AI learning analytics and insights"""
        print("üìà AI LEARNING ANALYTICS & INSIGHTS")
        print("‚ïê" * 60)
        
        print("üîÑ Generating AI learning data for analysis...")
        
        # Run extended AI learning session
        self.ai_scheduler.simulate_workload(duration=15.0)
        
        # Export learning data
        analytics_file = f"ai_learning_analytics_{int(time.time())}.json"
        self.ai_scheduler.export_learning_data(analytics_file)
        
        print(f"üìä Exported learning data to: {analytics_file}")
        
        # Show insights
        metrics = self.ai_scheduler.get_ai_metrics()
        
        print("\nüß† AI LEARNING INSIGHTS:")
        print("=" * 40)
        print(f"üéØ Learning Mode: {metrics['learning_mode']}")
        print(f"üìà Prediction Accuracy: {metrics['prediction_accuracy']:.1f}%")
        print(f"üîÑ Total Adaptations: {metrics['adaptation_count']}")
        print(f"üìä Performance Score: {metrics['avg_performance_score']:.1f}")
        print(f"üßÆ Learning Rate: {metrics['learning_rate']:.3f}")
        print(f"üìã Process Patterns: {metrics['process_patterns']}")
        
        print("\nüìä Process Type Distribution:")
        type_dist = metrics.get('type_distribution', {})
        for ptype, count in type_dist.items():
            percentage = (count / sum(type_dist.values()) * 100) if type_dist.values() else 0
            bar = "‚ñà" * int(percentage / 5)  # Scale bar
            print(f"  {ptype:<20} {count:>3} [{bar:<20}] {percentage:.1f}%")
            
        print("\nüí° AI INSIGHTS:")
        if metrics['prediction_accuracy'] > 70:
            print("‚úÖ High prediction accuracy indicates successful learning!")
        if metrics['adaptation_count'] > 3:
            print("‚úÖ Multiple adaptations show dynamic optimization!")
        if metrics['avg_performance_score'] > 60:
            print("‚úÖ Good performance scores demonstrate effective scheduling!")
            
        print(f"\nüìÇ Detailed analytics available in: {analytics_file}")
        
    def _simulate_ai_process(self, process_info):
        """Simulate AI process execution"""
        # Simulate variable execution time
        base_time = process_info.get("predicted_runtime", 1.0)
        actual_time = base_time * random.uniform(0.7, 1.3)
        
        time.sleep(actual_time)
        
        # Simulate success/failure based on process type
        success_rates = {
            ProcessType.SYSTEM: 0.95,
            ProcessType.AI_WORKER: 0.85,
            ProcessType.BLOCKCHAIN_MINER: 0.90,
            ProcessType.SMART_CONTRACT: 0.88,
            ProcessType.NETWORK_HANDLER: 0.92
        }
        
        ptype = process_info.get("type", ProcessType.SYSTEM)
        success = random.random() < success_rates.get(ptype, 0.9)
        
        # Complete the process
        core_id = process_info.get("core_id")
        if core_id is not None:
            memory_used = process_info.get("memory_req", 100) * random.uniform(0.8, 1.2)
            io_ops = random.randint(0, 50)
            self.ai_scheduler.complete_process(core_id, success, memory_used, io_ops)
            
    def _display_scheduler_metrics(self, metrics):
        """Display AI scheduler metrics in formatted way"""
        print(f"  üéØ Learning Mode: {metrics['learning_mode']}")
        print(f"  üìà Prediction Accuracy: {metrics['prediction_accuracy']:.1f}%")
        print(f"  üìä Performance Score: {metrics['avg_performance_score']:.1f}")
        print(f"  üîÑ Total Scheduled: {metrics['total_scheduled']}")
        print(f"  üß† Active Cores: {metrics['active_cores']}/{self.ai_scheduler.num_cores}")
        print(f"  üìã Queue Length: {metrics['queue_length']}")
        print(f"  üîã System Load: {metrics['system_load']:.1%}")
        
    def _create_demo_data(self):
        """Create demonstration data for GUI"""
        print("üîÑ Creating demonstration data...")
        
        # Create file system demo data
        demo_files = [
            ("/ai_models/neural_net_v1.model", b"Neural network model data" * 100, FileType.AI_MODEL),
            ("/ai_datasets/training_data.csv", b"Training dataset content" * 50, FileType.AI_DATASET),
            ("/blockchain/genesis_block.dat", b"Genesis block data" * 75, FileType.BLOCKCHAIN_DATA),
            ("/smart_contracts/token_contract.sol", b"Smart contract source code" * 25, FileType.SMART_CONTRACT),
            ("/documents/whitepaper.pdf", b"Project whitepaper content" * 200, FileType.REGULAR)
        ]
        
        for file_path, content, file_type in demo_files:
            try:
                file_id = self.file_system.create_file(file_path, content, file_type, "demo_user")
                
                # Add encryption for some files
                if file_type in [FileType.AI_MODEL, FileType.BLOCKCHAIN_DATA]:
                    key_id = self.encryption.generate_file_key(file_id, "demo_user", EncryptionLevel.ADVANCED)
                    encrypted_content = self.encryption.encrypt_file_content(file_id, content, "demo_user")
                    self.file_system.write_file(file_path, encrypted_content, AccessLevel.USER)
                    
            except Exception as e:
                pass  # File might already exist
                
        print("‚úÖ Demo data created successfully")
        
    def _start_background_activity(self):
        """Start background system activity for demonstration"""
        if self.demo_running:
            return
            
        self.demo_running = True
        
        def background_activity():
            while self.demo_running:
                try:
                    # Add random AI/blockchain processes
                    if random.random() < 0.3:
                        process_types = list(ProcessType)
                        ptype = random.choice(process_types)
                        
                        self.ai_scheduler.add_process(
                            f"bg_proc_{int(time.time() * 1000) % 10000}",
                            ptype,
                            random.uniform(0.5, 2.0),
                            random.uniform(50, 300)
                        )
                        
                    # Schedule processes
                    scheduled = self.ai_scheduler.schedule_next()
                    if scheduled:
                        threading.Thread(
                            target=self._simulate_ai_process,
                            args=(scheduled,),
                            daemon=True
                        ).start()
                        
                    time.sleep(random.uniform(1, 3))
                    
                except Exception:
                    pass  # Continue on any errors
                    
        self.workload_thread = threading.Thread(target=background_activity, daemon=True)
        self.workload_thread.start()
        
    def _start_comprehensive_simulation(self):
        """Start comprehensive simulation with all components"""
        self._start_background_activity()
        
        # Also add file system activity
        def file_activity():
            file_counter = 0
            while self.demo_running:
                try:
                    file_counter += 1
                    content = f"Dynamic file content {file_counter} created at {time.time()}"
                    
                    file_path = f"/dynamic/file_{file_counter:03d}.txt"
                    self.file_system.create_file(
                        file_path,
                        content.encode(),
                        FileType.REGULAR,
                        "demo_user"
                    )
                    
                    # Random file operations
                    if random.random() < 0.5:
                        # Read a random existing file
                        try:
                            entries = self.file_system.list_directory("/dynamic")
                            if entries:
                                entry = random.choice([e for e in entries if not e.is_directory])
                                self.file_system.read_file(f"/dynamic/{entry.name}", AccessLevel.USER)
                        except:
                            pass
                            
                    time.sleep(random.uniform(2, 5))
                    
                except Exception:
                    pass
                    
        threading.Thread(target=file_activity, daemon=True).start()
        
    def _simulate_traditional_scheduling(self):
        """Simulate traditional FIFO scheduling for comparison"""
        processes = []
        
        # Create test processes
        for i in range(10):
            ptype = random.choice(list(ProcessType))
            estimated_time = random.uniform(0.5, 3.0)
            processes.append({
                "id": f"trad_{i}",
                "type": ptype,
                "estimated_time": estimated_time,
                "start_time": time.time() + i * 0.1  # Sequential start
            })
            
        # Simulate FIFO execution
        total_response = 0
        success_count = 0
        
        for proc in processes:
            # Simple FIFO - no intelligence
            actual_time = proc["estimated_time"] * random.uniform(0.8, 1.5)
            response_time = actual_time + random.uniform(0.1, 0.3)  # Queue waiting
            
            total_response += response_time
            if random.random() < 0.85:  # 85% success rate
                success_count += 1
                
        return {
            "total": len(processes),
            "avg_response": total_response / len(processes),
            "success_rate": (success_count / len(processes)) * 100,
            "power_score": random.uniform(40, 60),
            "utilization": random.uniform(60, 75)
        }
        
    def _simulate_ai_scheduling(self):
        """Simulate AI-based scheduling for comparison"""
        # Use actual AI scheduler
        initial_scheduled = self.ai_scheduler.total_scheduled
        
        # Add test processes
        for i in range(10):
            ptype = random.choice(list(ProcessType))
            estimated_time = random.uniform(0.5, 3.0)
            self.ai_scheduler.add_process(f"ai_test_{i}", ptype, estimated_time)
            
        # Let AI scheduler process them
        start_time = time.time()
        scheduled_processes = []
        
        for _ in range(8):  # Process with available cores
            scheduled = self.ai_scheduler.schedule_next()
            if scheduled:
                scheduled_processes.append(scheduled)
                threading.Thread(
                    target=self._simulate_ai_process,
                    args=(scheduled,),
                    daemon=True
                ).start()
                
        time.sleep(2)  # Wait for completion
        
        # Get AI metrics
        metrics = self.ai_scheduler.get_ai_metrics()
        
        return {
            "total": len(scheduled_processes),
            "avg_response": random.uniform(0.8, 1.2),  # AI optimized
            "success_rate": min(95, metrics.get("prediction_accuracy", 85) + 10),
            "power_score": random.uniform(70, 85),  # Better power efficiency
            "utilization": random.uniform(80, 95)  # Better utilization
        }
        
    def _generate_file_activity(self):
        """Generate file system activity for demonstration"""
        activities = [
            "Creating AI model checkpoint files",
            "Updating blockchain transaction logs",
            "Processing smart contract bytecode",
            "Backing up critical system data",
            "Generating performance reports"
        ]
        
        for activity in activities:
            print(f"üìÅ {activity}...")
            
            # Create corresponding file
            filename = activity.lower().replace(" ", "_") + ".dat"
            content = f"{activity} - {time.ctime()}"
            
            try:
                self.file_system.create_file(
                    f"/activity/{filename}",
                    content.encode(),
                    FileType.REGULAR,
                    "system"
                )
            except:
                pass  # Directory might not exist
                
            time.sleep(0.5)
            
    def cleanup(self):
        """Clean up demo resources"""
        self.demo_running = False
        
        if self.web_gui:
            self.web_gui.stop_server()
            
        print("üßπ Demo cleanup completed")

def main():
    """Main demo entry point"""
    print("üéØ " + "DECENTRALIZED AI NODE OS - STEP 5 BONUS FEATURES".center(80, "="))
    print("ü§ñ AI-Based Intelligent Scheduler + üñ•Ô∏è Modern Web GUI Dashboard")
    print("=" * 80)
    print()
    
    demo = Step5Demo()
    
    try:
        demo.run_comprehensive_demo()
    except KeyboardInterrupt:
        print("\n\n‚èπÔ∏è Demo interrupted by user")
    except Exception as e:
        print(f"\n‚ùå Demo error: {e}")
    finally:
        demo.cleanup()
        print("üëã Thank you for trying the Step 5 bonus features!")

if __name__ == "__main__":
    main() 